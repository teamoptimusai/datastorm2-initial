{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datastorm-BimsaraV3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Y3_Ry5-AHS"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX-dWz6095Ls",
        "outputId": "5f0502cb-15bb-412d-bcfa-557421cad31a"
      },
      "source": [
        "!gdown --id 1MIKKj8Gi-xUwhsYt6xEV6FSmX0_Le8iL\n",
        "!unzip -q 'data-storm-20.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MIKKj8Gi-xUwhsYt6xEV6FSmX0_Le8iL\n",
            "To: /content/data-storm-20.zip\n",
            "\r  0% 0.00/1.23M [00:00<?, ?B/s]\r100% 1.23M/1.23M [00:00<00:00, 38.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36wdapDi-EDb"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts4i48f3-FWp",
        "outputId": "4aa234c7-6c6d-4b9f-9e6f-239013303a7a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler,Normalizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "#from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "!pip install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11687 sha256=8f8e93e8580dcdae851134f49e88a9769917e89fbc4df72b012092cef6b67773\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE_sUMTnJbNL"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7rPMHKL-OWJ"
      },
      "source": [
        "# Dataset function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkZSKBpQ-UO3"
      },
      "source": [
        "def preprocessing_data(filename):\n",
        "\n",
        "  df = pd.read_csv(filename)\n",
        "\n",
        "  object_cols = ['Gender', 'Ethnicity', 'Educational_Level',\n",
        "       'Income', 'Country_region', 'Hotel_Type', \n",
        "       'Meal_Type', 'Visted_Previously', 'Previous_Cancellations',\n",
        "       'Deposit_type', 'Booking_channel', 'Required_Car_Parking',\n",
        "       'Reservation_Status', 'Use_Promotion'] \n",
        "\n",
        "  dates = ['Expected_checkin', 'Expected_checkout', 'Booking_date']\n",
        "\n",
        "  one_hot_encoded_lst = ['Ethnicity', 'Educational_Level',\n",
        "       'Income', 'Country_region', 'Hotel_Type', \n",
        "       'Meal_Type', 'Deposit_type', 'Booking_channel'] \n",
        "\n",
        "  df = pd.get_dummies(df, columns=one_hot_encoded_lst) #one hot encoding\n",
        "\n",
        "  df['Gender'] = df['Gender'].map({'F':0, 'M':1}) #categorising\n",
        "  df['Visted_Previously'] = df['Visted_Previously'].map({'No':0, 'Yes':1})\n",
        "  df['Previous_Cancellations'] = df['Previous_Cancellations'].map({'No':0, 'Yes':1})\n",
        "  df['Required_Car_Parking'] = df['Required_Car_Parking'].map({'Yes':1, 'No':0})\n",
        "  df['Use_Promotion'] = df['Use_Promotion'].map({'Yes':1, 'No':0})\n",
        "  df['Reservation_Status'] = df['Reservation_Status'].map({'Check-In':0, 'Canceled':1, 'No-Show':2})\n",
        "\n",
        "  df[dates[0]] = pd.to_datetime(df[dates[0]]) #dates engineering\n",
        "  df[dates[1]] = pd.to_datetime(df[dates[1]])\n",
        "  df[dates[2]] = pd.to_datetime(df[dates[2]])\n",
        "\n",
        "  df['Expected_stay'] = (df[dates[1]] - df[dates[0]]).dt.days\n",
        "\n",
        "  df['Booking_to_checkingin'] = (df[dates[0]] - df[dates[2]]).dt.days\n",
        "\n",
        "  weekdayin = df[dates[0]].dt.dayofweek\n",
        "\n",
        "  weekdayout = df[dates[1]].dt.dayofweek\n",
        "  from pandas import DataFrame\n",
        "\n",
        "  fina = []\n",
        "  for x,y in zip(weekdayin, weekdayout):\n",
        "    t = []\n",
        "    if y >= x:\n",
        "      for i in range(x, y + 1):\n",
        "        t.append(i)\n",
        "      if 5 in t or 6 in t:\n",
        "        fina.append(1)\n",
        "      else:\n",
        "        fina.append(0)\n",
        "    else:\n",
        "      for i in range(x, 7):\n",
        "        t.append(i)\n",
        "      for j in range(0, y + 1):\n",
        "        t.append(i)\n",
        "      if 5 in t or 6 in t:\n",
        "        fina.append(1)\n",
        "      else:\n",
        "        fina.append(0)\n",
        "  xf = DataFrame (fina,columns=['weekend_stay'])\n",
        "  df['weekend_stay'] = xf\n",
        "\n",
        "  df['Month_of_stay'] = df[dates[0]].dt.month\n",
        "\n",
        "  df = df.drop(columns=dates)   #scaling\n",
        "\n",
        "  scale_lst = ['Age', 'Adults', 'Children', 'Babies', 'Discount_Rate', 'Room_Rate', 'Expected_stay', 'Booking_to_checkingin', 'Month_of_stay']\n",
        "\n",
        "  df[scale_lst] = StandardScaler().fit_transform(df[scale_lst])\n",
        "\n",
        "  X = df.drop(columns=['Reservation_Status', 'Reservation-id'])\n",
        "  y = df['Reservation_Status']\n",
        "\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAwJQejzb9UD"
      },
      "source": [
        "def preprocessing_test(filename):\n",
        "\n",
        "  df = pd.read_csv(filename)\n",
        "\n",
        "  object_cols = ['Gender', 'Ethnicity', 'Educational_Level',\n",
        "       'Income', 'Country_region', 'Hotel_Type', \n",
        "       'Meal_Type', 'Visted_Previously', 'Previous_Cancellations',\n",
        "       'Deposit_type', 'Booking_channel', 'Required_Car_Parking', 'Use_Promotion'] \n",
        "\n",
        "  dates = ['Expected_checkin', 'Expected_checkout', 'Booking_date']\n",
        "\n",
        "  one_hot_encoded_lst = ['Ethnicity', 'Educational_Level',\n",
        "       'Income', 'Country_region', 'Hotel_Type', \n",
        "       'Meal_Type', 'Deposit_type', 'Booking_channel'] \n",
        "\n",
        "  df = pd.get_dummies(df, columns=one_hot_encoded_lst) #one hot encoding\n",
        "\n",
        "  df['Gender'] = df['Gender'].map({'F':0, 'M':1}) #categorising\n",
        "  df['Visted_Previously'] = df['Visted_Previously'].map({'No':0, 'Yes':1})\n",
        "  df['Previous_Cancellations'] = df['Previous_Cancellations'].map({'No':0, 'Yes':1})\n",
        "  df['Required_Car_Parking'] = df['Required_Car_Parking'].map({'Yes':1, 'No':0})\n",
        "  df['Use_Promotion'] = df['Use_Promotion'].map({'Yes':1, 'No':0})\n",
        "  #df['Reservation_Status'] = df['Reservation_Status'].map({'Check-In':0, 'Canceled':1, 'No-Show':2})\n",
        "\n",
        "  df[dates[0]] = pd.to_datetime(df[dates[0]]) #dates engineering\n",
        "  df[dates[1]] = pd.to_datetime(df[dates[1]])\n",
        "  df[dates[2]] = pd.to_datetime(df[dates[2]])\n",
        "\n",
        "  df['Expected_stay'] = (df[dates[1]] - df[dates[0]]).dt.days\n",
        "\n",
        "  df['Booking_to_checkingin'] = (df[dates[0]] - df[dates[2]]).dt.days\n",
        "\n",
        "  weekdayin = df[dates[0]].dt.dayofweek\n",
        "\n",
        "  weekdayout = df[dates[1]].dt.dayofweek\n",
        "  from pandas import DataFrame\n",
        "\n",
        "  fina = []\n",
        "  for x,y in zip(weekdayin, weekdayout):\n",
        "    t = []\n",
        "    if y >= x:\n",
        "      for i in range(x, y + 1):\n",
        "        t.append(i)\n",
        "      if 5 in t or 6 in t:\n",
        "        fina.append(1)\n",
        "      else:\n",
        "        fina.append(0)\n",
        "    else:\n",
        "      for i in range(x, 7):\n",
        "        t.append(i)\n",
        "      for j in range(0, y + 1):\n",
        "        t.append(i)\n",
        "      if 5 in t or 6 in t:\n",
        "        fina.append(1)\n",
        "      else:\n",
        "        fina.append(0)\n",
        "  xf = DataFrame (fina,columns=['weekend_stay'])\n",
        "  df['weekend_stay'] = xf\n",
        "\n",
        "  df['Month_of_stay'] = df[dates[0]].dt.month\n",
        "\n",
        "  df = df.drop(columns=dates)   #scaling\n",
        "\n",
        "  scale_lst = ['Age', 'Adults', 'Children', 'Babies', 'Discount_Rate', 'Room_Rate', 'Expected_stay', 'Booking_to_checkingin', 'Month_of_stay']\n",
        "\n",
        "  df[scale_lst] = StandardScaler().fit_transform(df[scale_lst])\n",
        "\n",
        "  X = df.drop(columns=['Reservation-id'])\n",
        "  #y = df['Reservation_Status']\n",
        "\n",
        "  return X #, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFXwRbxQEf7Q"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXcKn3PH_5p0",
        "outputId": "988502a5-a363-4c9e-92f3-b5f774fd0d5c"
      },
      "source": [
        "X_train, y_train = preprocessing_data('Hotel-A-train.csv')\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27499, 43), (27499,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQnaiWqcEAFQ",
        "outputId": "6263a75a-1497-47ab-87db-bc1151a2bd00"
      },
      "source": [
        "X_val, y_val = preprocessing_data('Hotel-A-validation.csv')\n",
        "X_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2749, 43), (2749,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73WZ7OZ1ELqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f525aa-9fde-4a9c-b7f0-e85923bcc29f"
      },
      "source": [
        "X_test = preprocessing_test('Hotel-A-test.csv')\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4318, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogb3Gy8OlMJe"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(.95)\n",
        "pca.fit(X_train)\n",
        "X_train = pca.transform(X_train)\n",
        "X_val = pca.transform(X_val)\n",
        "X_test = pca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PG0oZ_wE-G0"
      },
      "source": [
        "# SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KUhTMaEE9MY",
        "outputId": "2e133e73-75ca-44ec-a93b-47bdf1f0b265"
      },
      "source": [
        "print(\"Before OverSampling, counts of label '0': {}\".format(sum(y_train == 0))) \n",
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
        "print(\"Before OverSampling, counts of label '2': {} \\n\".format(sum(y_train == 2))) \n",
        "\n",
        "# import SMOTE module from imblearn library \n",
        "# pip install imblearn (if you don't have imblearn in your system) \n",
        "\n",
        "over = SMOTE()\n",
        "under = RandomUnderSampler()\n",
        "\n",
        "#X_train_res, y_train_res = under.fit_sample(X_train, y_train.ravel()) \n",
        "X_train_res, y_train_res = over.fit_sample(X_train, y_train.ravel()) \n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
        "\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) \n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
        "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res == 2))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '0': 21240\n",
            "Before OverSampling, counts of label '1': 4134\n",
            "Before OverSampling, counts of label '2': 2125 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After OverSampling, the shape of train_X: (63720, 43)\n",
            "After OverSampling, the shape of train_y: (63720,) \n",
            "\n",
            "After OverSampling, counts of label '0': 21240\n",
            "After OverSampling, counts of label '1': 21240\n",
            "After OverSampling, counts of label '2': 21240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIzktjgpK4Z0"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx0YE7FLLvuS"
      },
      "source": [
        "Under and over sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F1CAT7UlgRb",
        "outputId": "ac8ba898-68a7-4511-f4b9-04fabc4ac8ad"
      },
      "source": [
        "X_train.shape, X_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27499, 30), (2749, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wAwR-s-rJv_A",
        "outputId": "8ff39690-cb0a-4d84-ccdf-7888d199836e"
      },
      "source": [
        "classifiers=[['Logistic Regression :',LogisticRegression()],\n",
        "       ['Decision Tree Classification :',DecisionTreeClassifier()],\n",
        "       ['Gradient Boosting Classification :', GradientBoostingClassifier()],\n",
        "       ['Ada Boosting Classification :',AdaBoostClassifier()],\n",
        "       ['Extra Tree Classification :', ExtraTreesClassifier()],\n",
        "       ['K-Neighbors Classification :',KNeighborsClassifier()]]\n",
        "       #['Support Vector Classification :',SVC()],\n",
        "       #['Gaussian Naive Bayes :',GaussianNB()]]\n",
        "\n",
        "cla_pred=[]\n",
        "\n",
        "for name,model in classifiers:\n",
        "\n",
        "    model=model\n",
        "    model.fit(X_train,y_train)\n",
        "    predictions = model.predict(X_val)\n",
        "    cla_pred.append(accuracy_score(y_val,predictions))\n",
        "\n",
        "    print(name)\n",
        "    print(confusion_matrix(y_val,predictions))\n",
        "    print(classification_report(y_val,predictions))\n",
        "    print(accuracy_score(y_val,predictions))\n",
        "    print(\"*********************************************\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression :\n",
            "[[1610    0    0]\n",
            " [ 741    0    0]\n",
            " [ 398    0    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      1.00      0.74      1610\n",
            "           1       0.00      0.00      0.00       741\n",
            "           2       0.00      0.00      0.00       398\n",
            "\n",
            "    accuracy                           0.59      2749\n",
            "   macro avg       0.20      0.33      0.25      2749\n",
            "weighted avg       0.34      0.59      0.43      2749\n",
            "\n",
            "0.5856675154601674\n",
            "*********************************************\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Decision Tree Classification :\n",
            "[[1179  278  153]\n",
            " [ 497  165   79]\n",
            " [ 278   82   38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.73      0.66      1610\n",
            "           1       0.31      0.22      0.26       741\n",
            "           2       0.14      0.10      0.11       398\n",
            "\n",
            "    accuracy                           0.50      2749\n",
            "   macro avg       0.35      0.35      0.35      2749\n",
            "weighted avg       0.46      0.50      0.47      2749\n",
            "\n",
            "0.5027282648235722\n",
            "*********************************************\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-fa856364285c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcla_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1245\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdRa_dqRLy3h"
      },
      "source": [
        "Over sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXGSz_3bLNo0",
        "outputId": "f111d024-d58b-4305-9926-7c4a14bf8a95"
      },
      "source": [
        "classifiers=[['Logistic Regression :',LogisticRegression()],\n",
        "       ['Decision Tree Classification :',DecisionTreeClassifier()],\n",
        "       ['Gradient Boosting Classification :', GradientBoostingClassifier()],\n",
        "       ['Ada Boosting Classification :',AdaBoostClassifier()],\n",
        "       ['Extra Tree Classification :', ExtraTreesClassifier()],\n",
        "       ['K-Neighbors Classification :',KNeighborsClassifier()],\n",
        "       ['Support Vector Classification :',SVC()],\n",
        "       ['Gaussian Naive Bayes :',GaussianNB()]]\n",
        "\n",
        "cla_pred=[]\n",
        "\n",
        "for name,model in classifiers:\n",
        "\n",
        "    model=model\n",
        "    model.fit(X_train_res,y_train_res)\n",
        "    predictions = model.predict(X_val)\n",
        "    cla_pred.append(accuracy_score(y_val,predictions))\n",
        "\n",
        "    print(name)\n",
        "    print(confusion_matrix(y_val,predictions))\n",
        "    print(classification_report(y_val,predictions))\n",
        "    print(accuracy_score(y_val,predictions))\n",
        "    print(\"*********************************************\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression :\n",
            "[[650 421 539]\n",
            " [271 190 280]\n",
            " [147 112 139]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.40      0.49      1610\n",
            "           1       0.26      0.26      0.26       741\n",
            "           2       0.15      0.35      0.21       398\n",
            "\n",
            "    accuracy                           0.36      2749\n",
            "   macro avg       0.34      0.34      0.32      2749\n",
            "weighted avg       0.45      0.36      0.38      2749\n",
            "\n",
            "0.3561295016369589\n",
            "*********************************************\n",
            "\n",
            "Decision Tree Classification :\n",
            "[[917 428 265]\n",
            " [398 213 130]\n",
            " [235  98  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.57      0.58      1610\n",
            "           1       0.29      0.29      0.29       741\n",
            "           2       0.14      0.16      0.15       398\n",
            "\n",
            "    accuracy                           0.43      2749\n",
            "   macro avg       0.34      0.34      0.34      2749\n",
            "weighted avg       0.44      0.43      0.44      2749\n",
            "\n",
            "0.4347035285558385\n",
            "*********************************************\n",
            "\n",
            "Gradient Boosting Classification :\n",
            "[[1004  524   82]\n",
            " [ 454  246   41]\n",
            " [ 242  136   20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.62      0.61      1610\n",
            "           1       0.27      0.33      0.30       741\n",
            "           2       0.14      0.05      0.07       398\n",
            "\n",
            "    accuracy                           0.46      2749\n",
            "   macro avg       0.33      0.34      0.33      2749\n",
            "weighted avg       0.44      0.46      0.45      2749\n",
            "\n",
            "0.46198617679156057\n",
            "*********************************************\n",
            "\n",
            "Ada Boosting Classification :\n",
            "[[ 532 1031   47]\n",
            " [ 222  494   25]\n",
            " [ 141  246   11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.33      0.42      1610\n",
            "           1       0.28      0.67      0.39       741\n",
            "           2       0.13      0.03      0.05       398\n",
            "\n",
            "    accuracy                           0.38      2749\n",
            "   macro avg       0.34      0.34      0.29      2749\n",
            "weighted avg       0.44      0.38      0.36      2749\n",
            "\n",
            "0.37722808293925064\n",
            "*********************************************\n",
            "\n",
            "Extra Tree Classification :\n",
            "[[1573   31    6]\n",
            " [ 708   26    7]\n",
            " [ 380   17    1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.98      0.74      1610\n",
            "           1       0.35      0.04      0.06       741\n",
            "           2       0.07      0.00      0.00       398\n",
            "\n",
            "    accuracy                           0.58      2749\n",
            "   macro avg       0.34      0.34      0.27      2749\n",
            "weighted avg       0.45      0.58      0.45      2749\n",
            "\n",
            "0.5820298290287377\n",
            "*********************************************\n",
            "\n",
            "K-Neighbors Classification :\n",
            "[[467 639 504]\n",
            " [206 309 226]\n",
            " [121 150 127]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.29      0.39      1610\n",
            "           1       0.28      0.42      0.34       741\n",
            "           2       0.15      0.32      0.20       398\n",
            "\n",
            "    accuracy                           0.33      2749\n",
            "   macro avg       0.34      0.34      0.31      2749\n",
            "weighted avg       0.44      0.33      0.35      2749\n",
            "\n",
            "0.32848308475809385\n",
            "*********************************************\n",
            "\n",
            "Support Vector Classification :\n",
            "[[1357  165   88]\n",
            " [ 621   88   32]\n",
            " [ 335   40   23]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.84      0.69      1610\n",
            "           1       0.30      0.12      0.17       741\n",
            "           2       0.16      0.06      0.09       398\n",
            "\n",
            "    accuracy                           0.53      2749\n",
            "   macro avg       0.35      0.34      0.32      2749\n",
            "weighted avg       0.45      0.53      0.46      2749\n",
            "\n",
            "0.5340123681338669\n",
            "*********************************************\n",
            "\n",
            "Gaussian Naive Bayes :\n",
            "[[796 404 410]\n",
            " [335 193 213]\n",
            " [212  97  89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.49      0.54      1610\n",
            "           1       0.28      0.26      0.27       741\n",
            "           2       0.12      0.22      0.16       398\n",
            "\n",
            "    accuracy                           0.39      2749\n",
            "   macro avg       0.33      0.33      0.32      2749\n",
            "weighted avg       0.44      0.39      0.41      2749\n",
            "\n",
            "0.392142597308112\n",
            "*********************************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZvIKO9tqeiO"
      },
      "source": [
        "# Gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "EZsxitAmqgbV",
        "outputId": "e0d66825-25a2-4c5f-a1fe-f552c0d3f866"
      },
      "source": [
        "# n_estimators = [10, 20, 50, 100]\n",
        "# max_depth = [5,10,15,20]\n",
        "hyperparameters = [{'criterion': ['entropy', 'gini'], 'max_depth': range(1, 100, 1)}]\n",
        "\n",
        "dtmodel = DecisionTreeClassifier()\n",
        "h_dtmodel = GridSearchCV(dtmodel, hyperparameters, cv=5, verbose=0, scoring='f1_macro')\n",
        "\n",
        "best_logmodel = h_dtmodel.fit(X_train_res, y_train_res)\n",
        "\n",
        "print('Best criterion:', best_logmodel.best_estimator_.get_params()['criterion'])\n",
        "print('Best Max Depth:', best_logmodel.best_estimator_.get_params()['max_depth'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-734b36a01ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mh_dtmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbest_logmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_dtmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best criterion:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_logmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'criterion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_9OtNT-sFQK",
        "outputId": "5a4ec4be-deef-45bc-d227-0dca276053d3"
      },
      "source": [
        "dtmodel = DecisionTreeClassifier()\n",
        "\n",
        "dtmodel.fit(X_train, y_train)\n",
        "predictions = dtmodel.predict(X_val)\n",
        "\n",
        "print(confusion_matrix(y_val,predictions))\n",
        "print(classification_report(y_val,predictions))\n",
        "print(accuracy_score(y_val,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1191  269  150]\n",
            " [ 504  160   77]\n",
            " [ 273   82   43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.74      0.67      1610\n",
            "           1       0.31      0.22      0.26       741\n",
            "           2       0.16      0.11      0.13       398\n",
            "\n",
            "    accuracy                           0.51      2749\n",
            "   macro avg       0.36      0.35      0.35      2749\n",
            "weighted avg       0.46      0.51      0.48      2749\n",
            "\n",
            "0.5070934885412878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4rL5OdaNvmG"
      },
      "source": [
        "# Bayesian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L_z1LNiPSta"
      },
      "source": [
        "# X_train_res.shape, y_train_res.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWvlQBVcPks0"
      },
      "source": [
        "# X_train_res_pd = pd.DataFrame(X_train_res)\n",
        "# y_train_res_pd = pd.DataFrame(y_train_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R8eyRXYSfT3"
      },
      "source": [
        "# X_train_res_pd.shape, y_train_res_pd.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOwCzEoGaA-g"
      },
      "source": [
        "# y_train_res_pd[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvVM1aZ4L4nq"
      },
      "source": [
        "# #LGBMClassifier\n",
        "\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# from lightgbm import LGBMClassifier\n",
        "\n",
        "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# def lgbm_evaluate(**params):\n",
        "# #     warnings.simplefilter('ignore')\n",
        "    \n",
        "#     params['num_leaves'] = int(params['num_leaves'])\n",
        "#     params['max_depth'] = int(params['max_depth'])\n",
        "        \n",
        "#     clf = LGBMClassifier(**params, n_estimators=20000, nthread=-1)\n",
        "\n",
        "#     test_pred_proba = np.zeros((X_train_res_pd.shape[0], 3))\n",
        "    \n",
        "#     for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train_res_pd, y_train_res_pd)):\n",
        "#         X_train_bo, X_valid = X_train_res_pd.iloc[train_idx], X_train_res_pd.iloc[valid_idx]\n",
        "#         y_train_bo, y_valid = y_train_res_pd[0].iloc[train_idx], y_train_res_pd[0].iloc[valid_idx]\n",
        "        \n",
        "#         model = LGBMClassifier(**params, n_estimators = 10000, n_jobs = -1)\n",
        "#         model.fit(X_train_bo, y_train_bo, \n",
        "#                 eval_set=[(X_train_bo, y_train_bo), (X_valid, y_valid)], eval_metric='binary_logloss',\n",
        "#                 verbose=False, early_stopping_rounds=200)\n",
        "\n",
        "#         y_pred_valid = model.predict_proba(X_valid)\n",
        "\n",
        "#         test_pred_proba[valid_idx] = y_pred_valid\n",
        "\n",
        "#     return accuracy_score(y_valid, y_pred_valid.argmax(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGR4ZD5tN6JY"
      },
      "source": [
        "# #hyper parameter tuning\n",
        "# params = {'colsample_bytree': (0.8, 1),\n",
        "#      'learning_rate': (.001, .01), \n",
        "#       'num_leaves': (8, 128), \n",
        "#       'subsample': (0.4, 1), \n",
        "#       'max_depth': (16, 32), \n",
        "#       # 'reg_alpha': (.05, 15.0), \n",
        "#       # 'reg_lambda': (.05, 15.0), \n",
        "#       'min_split_gain': (.001, .02),\n",
        "#       'min_child_weight': (12, 80)}\n",
        "\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# n_fold = 20\n",
        "# folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
        "\n",
        "# from bayes_opt import BayesianOptimization\n",
        "# bo = BayesianOptimization(lgbm_evaluate, params)\n",
        "# bo.maximize(init_points=5, n_iter=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak8k7oOhPA3E"
      },
      "source": [
        "# params = {'num_leaves': int(bo.max['params']['num_leaves']), #parameter finding\n",
        "#           'min_data_in_leaf': int(bo.max['params']['min_child_weight']),\n",
        "#           'min_split_gain': bo.max['params']['min_split_gain'],\n",
        "#           'objective': 'binary',\n",
        "#           'max_depth': int(bo.max['params']['max_depth']),\n",
        "#           'learning_rate': bo.max['params']['learning_rate'],\n",
        "#           \"boosting\": \"gbdt\",\n",
        "#           \"bagging_freq\": 5,\n",
        "#           \"bagging_fraction\": bo.max['params']['subsample'],\n",
        "#           \"bagging_seed\": 11,\n",
        "#           \"verbosity\": -1,\n",
        "#           # 'reg_alpha': bo.max['params']['reg_alpha'],\n",
        "#           # 'reg_lambda': bo.max['params']['reg_lambda'],\n",
        "#           \"num_class\": 1,\n",
        "#           'nthread': -1\n",
        "#          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEmBlBPpkB02"
      },
      "source": [
        "# params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qDZ7IQMkIa5"
      },
      "source": [
        "# from lightgbm import LGBMClassifier #model fitting\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# model = LGBMClassifier(**params, n_estimators = 100, n_jobs = -1)\n",
        "# model.fit(X_train, y_train, \n",
        "#         eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='binary_logloss',\n",
        "#         verbose=5000, early_stopping_rounds=1)\n",
        "\n",
        "# predictions = model.predict(X_val)\n",
        "# predictions_ = model.predict(X_train)\n",
        "\n",
        "# print(accuracy_score(y_val, predictions), accuracy_score(y_train, predictions_))\n",
        "# print(confusion_matrix(y_val, predictions))\n",
        "# print(classification_report(y_val, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6xFk0YQei0v"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "v2MgUO-TgS0P",
        "outputId": "38cf34b6-f5d2-49b4-acdc-149d8a0501f6"
      },
      "source": [
        "data_submission = pd.read_csv('Hotel-A-test.csv', index_col=0)\n",
        "data_submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Educational_Level</th>\n",
              "      <th>Income</th>\n",
              "      <th>Country_region</th>\n",
              "      <th>Hotel_Type</th>\n",
              "      <th>Expected_checkin</th>\n",
              "      <th>Expected_checkout</th>\n",
              "      <th>Booking_date</th>\n",
              "      <th>Adults</th>\n",
              "      <th>Children</th>\n",
              "      <th>Babies</th>\n",
              "      <th>Meal_Type</th>\n",
              "      <th>Visted_Previously</th>\n",
              "      <th>Previous_Cancellations</th>\n",
              "      <th>Deposit_type</th>\n",
              "      <th>Booking_channel</th>\n",
              "      <th>Required_Car_Parking</th>\n",
              "      <th>Use_Promotion</th>\n",
              "      <th>Discount_Rate</th>\n",
              "      <th>Room_Rate</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reservation-id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62931593</th>\n",
              "      <td>F</td>\n",
              "      <td>52</td>\n",
              "      <td>Latino</td>\n",
              "      <td>Grad</td>\n",
              "      <td>25K --50K</td>\n",
              "      <td>South</td>\n",
              "      <td>City Hotel</td>\n",
              "      <td>11/18/2016</td>\n",
              "      <td>11/19/2016</td>\n",
              "      <td>10/28/2016</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>HB</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>Direct</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>10</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70586099</th>\n",
              "      <td>F</td>\n",
              "      <td>47</td>\n",
              "      <td>Latino</td>\n",
              "      <td>Grad</td>\n",
              "      <td>25K --50K</td>\n",
              "      <td>East</td>\n",
              "      <td>Airport Hotels</td>\n",
              "      <td>11/18/2016</td>\n",
              "      <td>11/19/2016</td>\n",
              "      <td>8/6/2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>FB</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>Online</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4230648</th>\n",
              "      <td>F</td>\n",
              "      <td>28</td>\n",
              "      <td>Asian American</td>\n",
              "      <td>Grad</td>\n",
              "      <td>&lt;25K</td>\n",
              "      <td>East</td>\n",
              "      <td>City Hotel</td>\n",
              "      <td>4/28/2017</td>\n",
              "      <td>5/1/2017</td>\n",
              "      <td>4/8/2017</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>BB</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>Agent</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25192322</th>\n",
              "      <td>F</td>\n",
              "      <td>65</td>\n",
              "      <td>caucasian</td>\n",
              "      <td>High-School</td>\n",
              "      <td>25K --50K</td>\n",
              "      <td>South</td>\n",
              "      <td>Airport Hotels</td>\n",
              "      <td>11/18/2016</td>\n",
              "      <td>11/20/2016</td>\n",
              "      <td>5/20/2016</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>FB</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>Online</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>10</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80931528</th>\n",
              "      <td>M</td>\n",
              "      <td>45</td>\n",
              "      <td>African American</td>\n",
              "      <td>College</td>\n",
              "      <td>25K --50K</td>\n",
              "      <td>South</td>\n",
              "      <td>City Hotel</td>\n",
              "      <td>11/18/2016</td>\n",
              "      <td>11/20/2016</td>\n",
              "      <td>10/31/2016</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>BB</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Refundable</td>\n",
              "      <td>Agent</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Gender  Age  ... Discount_Rate Room_Rate\n",
              "Reservation-id              ...                        \n",
              "62931593            F   52  ...            10       153\n",
              "70586099            F   47  ...             0       210\n",
              "4230648             F   28  ...             5       117\n",
              "25192322            F   65  ...            10       107\n",
              "80931528            M   45  ...             0       119\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixbv-phZk43x"
      },
      "source": [
        "submission_predictions = dtmodel.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvSZgVn7fBdT",
        "outputId": "ec19bc75-a253-46f1-956e-0a17efbd1c08"
      },
      "source": [
        "submission_predictions = submission_predictions.tolist()\n",
        "submission_predictions = [x + 1 for x in submission_predictions]\n",
        "submission_predictions.count(1), submission_predictions.count(2), submission_predictions.count(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3042, 817, 459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WUkWIh5fEQX"
      },
      "source": [
        "col_drop = data_submission.columns.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7utIOc68fFpc"
      },
      "source": [
        "submission = data_submission.drop(col_drop, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "dtlLjGXcgfOA",
        "outputId": "18062688-0b4e-4ff8-aeb5-28de91f1f8c7"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reservation-id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62931593</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70586099</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4230648</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25192322</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80931528</th>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: [62931593, 70586099, 4230648, 25192322, 80931528]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UgztMyXfIjJ"
      },
      "source": [
        "submission['Reservation_status'] = pd.DataFrame(submission_predictions,columns=['Reservation_status'])['Reservation_status'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "NH7nCrC0fJOj",
        "outputId": "e4c3a834-7ebc-42a3-aa2b-6fef801d7d36"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reservation_status</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reservation-id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62931593</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70586099</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4230648</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25192322</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80931528</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Reservation_status\n",
              "Reservation-id                    \n",
              "62931593                         1\n",
              "70586099                         3\n",
              "4230648                          1\n",
              "25192322                         1\n",
              "80931528                         2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfgcLXqefMSY"
      },
      "source": [
        "submission.to_csv('submission-2-day3_Bimsara3.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOHXsm7ugpCX",
        "outputId": "6e3e31d9-8a49-41ed-ff9e-f1ce1836564a"
      },
      "source": [
        "submission['Reservation_status'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3042\n",
              "2     817\n",
              "3     459\n",
              "Name: Reservation_status, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6fAONjEguvx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}